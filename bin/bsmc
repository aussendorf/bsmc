#!/usr/bin/python
# -*- coding: utf-8 -*-
# BAREOSÂ® - Backup Archiving REcovery Open Sourced
#
# Copyright (C) 2015-2015 Bareos GmbH & Co. KG
#
# This program is Free Software; you can redistribute it and/or
# modify it under the terms of version three of the GNU Affero General Public
# License as published by the Free Software Foundation, which is
# listed in the file LICENSE.
#
# This program is distributed in the hope that it will be useful, but
# WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU
# Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA
# 02110-1301, USA.
#
# Author: Maik Aussendorf
#
# PoC code to implement a Bareos commandline tool that allows to trigger
# common tasks from a Bareos client.
# bsmc stands for "Bareos simple management cli"
#
# Implemented are show scheduler, trigger incremental backup and restore a
# single given file.
#


import ConfigParser
import argparse
import bareos.bsock
import logging
import time
import sys
import re
import os
#import fcntl
import struct


def getArguments():
    '''
    CLI argument parser
    '''
    parser = argparse.ArgumentParser(description='CLI to Bareos director.', prog="bsmc")
    parser.add_argument('-d', '--debug', action='store_true', help="enable debugging output")
    parser.add_argument('-p', '--password', help="password to authenticate at Bareos Director")
    subparsers = parser.add_subparsers(help='Run \'bsmc subcommand help\'', dest='command')
    parser_query = subparsers.add_parser(
                    'query', help='query command is used to query information from director')
    parser_query.add_argument('queryobject', default='status',
                              choices=['sched', 'schedule', 'status'], help="Object to query")
    parser_incremental = subparsers.add_parser(
                    'incr', help = 'run incremental job(s) defined for this client')
    parser_restore = subparsers.add_parser(
                    'rest', help = "Restore a file or directory")
    parser_restore.add_argument('filename', help = "File or directory to restore")
    parser_restore.add_argument("-d", "--destination", help="Directory prefix for restore," +
                                " default =None, will restore to original place in filesystem",
                                default = None)
    parser_archive = subparsers.add_parser(
                    'archive', help = "Archive a list of files and / or directories")
    parser_archive.add_argument('filenames', nargs='+',
                    help = "list of files and / or directories to archive")
    args = parser.parse_args()
    return args
    
def query(queryobject, client):
    '''
    Query scheduler information for client
    '''
    if queryobject in ["sched", "schedule"]:
        command = "status scheduler client=" + client
        director.send(command)
        msg = director.recv_msg()
        sys.stdout.write(msg)
    elif queryobject in ['status', 'st']:
        command = "status client=" + client
        director.send(command)
        msg = director.recv_msg()
        sys.stdout.write(msg)
    else:
        logger.error("Unknown query object " + queryobject)

def waitForJob(jobId):
    '''
    Wait for a given job to finish and return a tupel (jobStatus, job message).
    Returns a tupel (char jobStatus, string jobMessage)

    Arguments
    jobID -- int job ID to wait for
    '''
    command = "wait jobid=%s" % jobId
    director.send(command)
    msg = director.recv_msg()
    pattern = re.compile('.*JobStatus=.*\((\w)\).*', re.MULTILINE)
    statusMatch = pattern.search(msg)
    if statusMatch is None:
        logger.error("No Job Status found for JobId=%d\n" % jobId)
        return (None, None)
    else:
        jobStatus = statusMatch.group(1)
        return (jobStatus, msg)


def incremental(client_joblist=None):
    '''
    Trigger incremental backup for client, using client_joblist
    Returns 0, if all jobs went fine, number of jobs with errors otherwise
    '''
    if client_joblist is None:
        # TODO: use all jobs configured for client instead of error here
        logger.error("No joblist configured. Use 'jobs' in [client] section" +
                     " of your bsmc config file")
        return 1
    errors = 0
    warnings = 0
    successful = 0
    jobList = []
    for job in client_joblist:
        backup_command = "run client=%s level=Incremental job=%s yes" % (client_fd, job)
        logger.debug("running %s\n" % backup_command)
        (jobId, jobStatus) = runJob(backup_command)
        if jobId is None:
            continue
        else:
            jobList.append(jobId)

    # now wait until all started jobs are done and report results
    for job in jobList:
        jobResult, jobMessage = waitForJob(job)

        if jobResult in ['E', 'f']:
            logger.error("Job %d finished with with status %s" % (job, jobResult))
            errors += 1
        elif jobResult in ['W', 'A']:
            logger.warning("Job %d finished with with status %s" % (job, jobResult))
            warnings += 1
        elif jobResult == 'T':
            logger.info("Job %d finished with with status %s" % (job, jobResult))
            successful += 1
        else:
            logger.warning("Job %d has unrecognized status %s" % (job, jobResult))
            warnings += 1

    logger.info("Run %d jobs, with %d warnings and %d errors."
                % (len(client_joblist), warnings, errors))
    return errors


def restoreFile(filename, relocation=None):
    '''
    Restore a single file. Returns 0, if file got restored without errors, 1 otherwise
    Arguments:
    filename -- The filename with full path to restore
    relocation -- Recover file to either a given directory or to a
    filename (if relocation is not a directory). Default: original filename
    '''
    filename = os.path.abspath(filename)
    filename = filename.encode('string-escape')
    where = '/'
    if relocation is None:
        relocationString = ''
    elif os.path.isdir(relocation):
        relocationString = "strip_prefix=.*/ add_prefix=/%s/" % relocation
    else:
        relocationString = "strip_prefix=.* add_prefix=%s" % relocation

    restore_command = ("restore file=%s client=%s %s where=%s yes"
                       % (filename, client_fd, relocationString, where))
    logger.debug("Command: %s" % restore_command)
    (jobId, jobResult) = runJob(restore_command, True)
    return jobResult in ['T']


def runJob(jobCommand, wait=False):
    '''
    Runs the job specified by jobCommand
    and return (jobId, None) if wait is false,
    otherwise wait until job has finished and return
    tupel (jobID, jobStatus), with jobSTatus in {E,f,W,A,T}
    '''
    director.send(jobCommand)
    msg = director.recv_msg()
    pattern = re.compile('.*JobId=(\d+).*', re.MULTILINE)
    idMatch = pattern.search(msg)
    if idMatch is None:
        logger.error("Warning: No JobId returned. Message was: %s" % msg)
        return (None, None)
    else:
        jobId = int(idMatch.group(1))
        logger.info("Job scheduled with JobId: %s" % jobId)

    if not wait:
        # TODO get and return jobStatus here (failed, running, waiting)
        return (jobId, None)

    (jobResult, jobMessage) = waitForJob(jobId)
    logger.debug("JobResult for job %d is: :%s, jobMessage: %s" % (jobId, jobResult, jobMessage))

    if jobResult in ['E', 'f']:
        logger.error("Job %d finished with with status %s. Message: %s"
                     % (jobId, jobResult, jobMessage))
    elif jobResult in ['W', 'A']:
        logger.warning("Job %d finished with with status %s. Message: %s"
                       % (jobId, jobResult, jobMessage))
    elif jobResult == 'T':
        logger.info("OK: Job %d finished with with status %s" % (jobId, jobResult))
    else:
        logger.warning("Job %d has unrecognized status %s. Message: %s"
                       % (jobId, jobResult, jobMessage))
        errors += 1
    return (jobId, jobResult)

def lockFile (fileName, waitIfLocked = False, waitIntervall = 1):
    '''
    Checks, if a file is locked by another process.
    fileName : Filename to lock (append a suffix and write pid to lockfile
    waitIfLocked: if true, wait until existings lock has disappeared
    waitIntervall: if waiting, then retry every n seconds set here
    returns success (true / false)
    '''
    lockFilename = fileName + ".lock"
    if os.path.isfile(lockFilename):
        if not waitIfLocked:
            logger.warning("File %s is locked by another process, quit." % fileName );
            return False
        else:
            logger.info("File %s is locked by another process. Waiting." % fileName)
    needLineBreak = False
    while os.path.isfile(lockFilename):
        time.sleep(waitIntervall)
        sys.stdout.write('.')
        sys.stdout.flush()
        needLineBreak = True
    f = open(lockFilename, "wb");
    f.write(str(os.getpid()))
    f.close()
    if needLineBreak:
        sys.stdout.write ('\n')
        sys.stdout.flush()
    return True

def unlockFile(fileName):
    '''
    Unlock a file previously locked with lockFile()
    '''
    lockFilename = fileName + ".lock"
    if not os.path.isfile(lockFilename):
        logger.warning("File %s is not locked, while trying to unlock it" % fileName);
    try:
        os.remove(lockFilename)
    except IOError as e:
        logger.error("Could not remove lockfile '%s'" % lockFilename)
        
def archiveFiles(fileNames):
    '''
    Creates a temporary filelist with files to backup
    and start a predefined archive job for those files
    '''
    if client_archivefilelist is None or client_archivejob is None:
        logger.error("Need archivejob and archivefilelist set in " +
                     "configuration file to run archive jobs")
        return 1
    lockFile(client_archivefilelist, waitIfLocked = True)
    fl = open(client_archivefilelist, "wb")
    
    for fileName in fileNames:
        absolute_filename = os.path.abspath(fileName)
        fl.write(absolute_filename)
        fl.write('\n')
    fl.close()
    jobCommand = "run client=%s job=%s yes" % (client_fd, client_archivejob)
    (jobId, jobResult) = runJob(jobCommand, True)
    try:
        os.remove(client_archivefilelist)
    except IOError as e:
        logger.warning("Could not remove file for archive files '%s'" % client_archivefilelist)
    unlockFile(client_archivefilelist)
    return jobResult in ['T']

if __name__ == '__main__':
    logging.basicConfig(format='%(levelname)s %(module)s.%(funcName)s: %(message)s',
                        level=logging.INFO)
    logger = logging.getLogger()

    args = getArguments()
    if args.debug:
        logger.setLevel(logging.DEBUG)

    parser = ConfigParser.SafeConfigParser({'port': '9101'})
    # TODO make configfile an option
    parser.readfp(open("/etc/bareos/bsmc.conf", "r"))

    host = parser.get("director", "server")
    dirname = parser.get("director", "name")
    password = parser.get("director", "password")
    dir_port = parser.getint("director", "port")
    # TODO: restructure client as directory
    client_fd = parser.get("client", "name")
    # Relevant jobs for this client to be run when triggering "incremental" jobs.
    if parser.has_option("client", "jobs"):
        client_joblist = parser.get("client", "jobs").split(',')
        logger.debug(client_joblist)
    else:
        client_joblist = None
    if parser.has_option("client", "archivejob"):
        client_archivejob = parser.get("client", "archivejob")
    else:
        client_archivejob = None

    if parser.has_option("client", "archivefilelist"):
        client_archivefilelist = parser.get("client", "archivefilelist")
    else:
        client_archivefilelist = None

    try:
        #director = bareos.bconsole(host, dir_port, dirname)
        director = bareos.bsock.BSock(address=host, port=dir_port, dirname=dirname, password=bareos.bsock.Password(password))
    except RuntimeError as e:
        print str(e)
        sys.exit(1)
    #if not director.login(password):
    #    logger.error("failed to authenticate")
    #    sys.exit(1)
    #logger.debug("authentication successful")
    #director.init()

    logger.debug("Command: " + args.command + "\n")

    if args.command in ["query", 'q']:
        query(args.queryobject, client_fd)
    elif args.command in ['Incremental', 'incr']:
        exitCode = incremental(client_joblist)
        sys.exit(exitCode)
    elif args.command in ['restore', 'rest']:
        jobDone = restoreFile(args.filename, args.destination)
        if jobDone:
            sys.exit(0)
        else:
            sys.exit(1)
    elif (args.command in ['archive', 'arch']):
        if archiveFiles(args.filenames):
           sys.exit(0)
